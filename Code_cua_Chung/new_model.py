# =============================================
#  üß† Hu·∫•n luy·ªán MLP cho nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu ti·∫øng Vi·ªát
#  Input: train.csv, valid.csv, test.csv (c√πng th∆∞ m·ª•c)
#  Output: model_mlp.pkl + scaler.pkl
# =============================================

import pandas as pd
import joblib
import os
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# -----------------------------
# 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu
# -----------------------------
df_train = pd.read_csv('train.csv')
df_valid = pd.read_csv('valid.csv')
df_test = pd.read_csv('test.csv')

print(f"Train: {len(df_train)} m·∫´u, Valid: {len(df_valid)}, Test: {len(df_test)}")

# -----------------------------
# 2Ô∏è‚É£ Chu·∫©n b·ªã d·ªØ li·ªáu
# -----------------------------
X_train = df_train.drop('label', axis=1)
y_train = df_train['label']

X_valid = df_valid.drop('label', axis=1)
y_valid = df_valid['label']

X_test = df_test.drop('label', axis=1)
y_test = df_test['label']

# -----------------------------
# 3Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu
# -----------------------------
scaler = StandardScaler()
scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train)
X_valid_scaled = scaler.transform(X_valid)
X_test_scaled = scaler.transform(X_test)

print("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a (StandardScaler).")

# -----------------------------
# 4Ô∏è‚É£ Hu·∫•n luy·ªán MLP (v·ªõi GridSearch nh·∫π)
# -----------------------------
param_grid = {
    'hidden_layer_sizes': [(128, 64), (256, 128, 64)],
    'activation': ['relu'],
    'solver': ['adam'],
    'alpha': [1e-4, 1e-3],  # regularization
    'learning_rate_init': [0.001, 0.0005]
}

print("üîç ƒêang t√¨m c·∫•u h√¨nh t·ªët nh·∫•t b·∫±ng GridSearchCV (m·∫•t v√†i ph√∫t)...")
mlp = MLPClassifier(max_iter=300, random_state=42)
grid = GridSearchCV(mlp, param_grid, cv=3, verbose=1, n_jobs=-1)
grid.fit(X_train_scaled, y_train)

best_model = grid.best_estimator_
print(f"‚úÖ C·∫•u h√¨nh t·ªët nh·∫•t: {grid.best_params_}")

# -----------------------------
# 5Ô∏è‚É£ ƒê√°nh gi√° tr√™n t·∫≠p VALID
# -----------------------------
valid_preds = best_model.predict(X_valid_scaled)
valid_acc = accuracy_score(y_valid, valid_preds)
print(f"\nüéØ Accuracy (VALID): {valid_acc * 100:.2f}%")

print("\nüìä B√°o c√°o chi ti·∫øt:")
print(classification_report(y_valid, valid_preds))

# -----------------------------
# 6Ô∏è‚É£ ƒê√°nh gi√° tr√™n t·∫≠p TEST
# -----------------------------
test_preds = best_model.predict(X_test_scaled)
test_acc = accuracy_score(y_test, test_preds)
print(f"\nüßæ Accuracy (TEST): {test_acc * 100:.2f}%")

# -----------------------------
# 8Ô∏è‚É£ L∆∞u model v√† scaler
# -----------------------------
MODEL_PATH = 'model_mlp.pkl'
SCALER_PATH = 'scaler.pkl'

joblib.dump(best_model, MODEL_PATH)
joblib.dump(scaler, SCALER_PATH)

print(f"\nüíæ ƒê√£ l∆∞u model: {MODEL_PATH}")
print(f"üíæ ƒê√£ l∆∞u scaler: {SCALER_PATH}")
print("üöÄ Hu·∫•n luy·ªán ho√†n t·∫•t!")